{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic simplest version\n",
    "In this file, using tf-idf with SVM abd Naive Bayes.  Comparing 50/50 80/20 90/10 data splits.\n",
    "\n",
    "Working with nltk version 3.2.5 and scikit-learn version 0.20.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# SVM\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# NB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # step by step reference, no pipeline\n",
    "\n",
    "# # count words\n",
    "# count_vect = CountVectorizer()\n",
    "# X_train_count = count_vect.fit_transform(X_train.text)\n",
    "# X_train_count.shape\n",
    "\n",
    "# # tf-idf\n",
    "# tfidf_transformer = TfidfTransformer()\n",
    "# X_train_tfidf = tfidf_transformer.fit_transform(X_train_count)\n",
    "# X_train_tfidf.shape\n",
    "\n",
    "# # NB\n",
    "# clf = MultinomialNB().fit(X_train_tfidf, X_train.author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "Using pipelines to help speed things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = Pipeline([(\"vect\", CountVectorizer()),\n",
    "                        (\"tfidf\", TfidfTransformer()),\n",
    "                        (\"clf-svm\", SGDClassifier(loss = \"hinge\", penalty = \"l2\",\n",
    "                                                tol = 1e-3, \n",
    "                                                random_state = 42)),])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clf = Pipeline([(\"vect\", CountVectorizer()),\n",
    "                    (\"tfidf\", TfidfTransformer()),\n",
    "                    (\"clf- nb\", MultinomialNB(),)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = Pipeline([(\"vect\", CountVectorizer()),\n",
    "                    (\"tfidf\", TfidfTransformer()),\n",
    "                    (\"clf-rf\", RandomForestClassifier(random_state = 42, n_estimators = 10),)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automate pipelines\n",
    "Create lists and a dictionary to help iterate through the fit and predict parts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = [svm_clf, nb_clf, rf_clf]\n",
    "pipe_dict = {0: \"Support Vector Machine\", 1: \"Naive Bayes\", 2: \"Random Forest\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting features, using bag of words model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                                               text author\n",
      "0  id26305  This process, however, afforded me no means of...    EAP\n",
      "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
      "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
      "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
      "4  id12958  Finding nothing else, not even gold, the Super...    HPL\n",
      "        id                                               text author\n",
      "0  id02310  Still, as I urged our leaving Ireland with suc...    MWS\n",
      "1  id00134  And when they had broken down the frail door t...    HPL\n",
      "2  id04081  I am not sure to what limit his knowledge may ...    EAP\n",
      "3  id25917  I sought for repose although I did not hope fo...    MWS\n",
      "4  id04951  Upon the fourth day of the assassination, a pa...    EAP\n"
     ]
    }
   ],
   "source": [
    "dataPath = os.path.join(os.getcwd(), \"data\", \"\")\n",
    "train = pd.read_csv(dataPath + \"train.csv\")\n",
    "test = pd.read_csv(dataPath + \"labeledTest.csv\")\n",
    "if(verbose):\n",
    "    print(train.head(5))\n",
    "    print(test.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of X50_train  (9789,)\n",
      "Shape of y50_train  (9789,)\n",
      "Shape of X50_test  (9790,)\n",
      "Shape of y50_test  (9790,)\n",
      "\n",
      "Shape of X80_train  (15663,)\n",
      "Shape of y20_train  (15663,)\n",
      "Shape of X80_test  (3916,)\n",
      "Shape of y20_test  (3916,)\n",
      "\n",
      "Shape of X90_train  (17621,)\n",
      "Shape of y10_train  (17621,)\n",
      "Shape of X90_train  (17621,)\n",
      "Shape of y10_train  (17621,)\n",
      "\n",
      "Shape of X_train  (19579,)\n",
      "Shape of y_train  (19579,)\n",
      "Shape of X_test  (4213,)\n",
      "Shape of y_test  (4213,)\n"
     ]
    }
   ],
   "source": [
    "X50_train, X50_test, y50_train, y50_test = train_test_split(train.text, train.author, test_size = .50)\n",
    "X80_train, X80_test, y20_train, y20_test = train_test_split(train.text, train.author, test_size = .20) \n",
    "X90_train, X90_test, y10_train, y10_test = train_test_split(train.text, train.author, test_size = .10)\n",
    "X_train = train.text\n",
    "y_train = train.author\n",
    "X_test = test.text\n",
    "y_test = test.author\n",
    "\n",
    "if(verbose):\n",
    "    print(\"\\nShape of X50_train \", X50_train.shape)\n",
    "    print(\"Shape of y50_train \", y50_train.shape)\n",
    "    print(\"Shape of X50_test \", X50_test.shape)\n",
    "    print(\"Shape of y50_test \", y50_test.shape)\n",
    "    \n",
    "    print(\"\\nShape of X80_train \", X80_train.shape)\n",
    "    print(\"Shape of y20_train \", y20_train.shape)\n",
    "    print(\"Shape of X80_test \", X80_test.shape)\n",
    "    print(\"Shape of y20_test \", y20_test.shape)\n",
    "    \n",
    "    print(\"\\nShape of X90_train \", X90_train.shape)\n",
    "    print(\"Shape of y10_train \", y10_train.shape)\n",
    "    print(\"Shape of X90_train \", X90_train.shape)\n",
    "    print(\"Shape of y10_train \", y10_train.shape)\n",
    "    \n",
    "    print(\"\\nShape of X_train \", X_train.shape)\n",
    "    print(\"Shape of y_train \", y_train.shape)\n",
    "    print(\"Shape of X_test \", X_test.shape)\n",
    "    print(\"Shape of y_test \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "X_train.append(X50_train)\n",
    "y_train.append(y50_train)\n",
    "X_test.append(X50_test)\n",
    "y_test.append(y50_test)\n",
    "    \n",
    "X_train.append(X80_train)\n",
    "y_train.append(y20_train)\n",
    "X_test.append(X80_test)\n",
    "y_test.append(y20_test)\n",
    "    \n",
    "X_train.append(X90_train)\n",
    "y_train.append(y10_train)\n",
    "X_test.append(X90_train)\n",
    "y_test.append(y10_train)\n",
    "\n",
    "\n",
    "\n",
    "train_dict = {0: \"50/50\", 1: \"80/20\", 2: \"90/10\", 3: \"full set\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Looking at 50/50 split\n",
      "\n",
      "Estimator: Support Vector Machine\n",
      "Test set accuracy score: 0.810 \n",
      "\n",
      "Estimator: Naive Bayes\n",
      "Test set accuracy score: 0.791 \n",
      "\n",
      "Estimator: Random Forest\n",
      "Test set accuracy score: 0.605 \n",
      "\n",
      "Looking at 80/20 split\n",
      "\n",
      "Estimator: Support Vector Machine\n",
      "Test set accuracy score: 0.827 \n",
      "\n",
      "Estimator: Naive Bayes\n",
      "Test set accuracy score: 0.813 \n",
      "\n",
      "Estimator: Random Forest\n",
      "Test set accuracy score: 0.611 \n",
      "\n",
      "Looking at 90/10 split\n",
      "\n",
      "Estimator: Support Vector Machine\n",
      "Test set accuracy score: 0.930 \n",
      "\n",
      "Estimator: Naive Bayes\n",
      "Test set accuracy score: 0.899 \n",
      "\n",
      "Estimator: Random Forest\n",
      "Test set accuracy score: 0.988 \n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(X_train):\n",
    "    \n",
    "    print(\"\\nLooking at\",  train_dict[i], \"split\")\n",
    "    accuracy[train_dict[i]] = {}\n",
    "    for idx, pl in enumerate(pipelines):\n",
    "        print(\"\\nEstimator:\",  pipe_dict[idx])\n",
    "        pl.fit(X_train[i], y_train[i])\n",
    "        y_pred = pl.predict(X_test[i])\n",
    "        print('Test set accuracy score: %.3f ' % accuracy_score(y_test[i], y_pred))\n",
    "        accuracy[train_dict[i]][pipe_dict[idx]] = accuracy_score(y_test[i], y_pred)\n",
    "        # end inner for over pipeline\n",
    "    #end outer for over data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Looking at 50/50 split\n",
      "\n",
      "Estimator: Support Vector Machine\n",
      "Test set accuracy score: 0.810 \n",
      "\n",
      "Estimator: Naive Bayes\n",
      "Test set accuracy score: 0.791 \n",
      "\n",
      "Estimator: Random Forest\n",
      "Test set accuracy score: 0.605 \n",
      "\n",
      "Looking at 80/20 split\n",
      "\n",
      "Estimator: Support Vector Machine\n",
      "Test set accuracy score: 0.827 \n",
      "\n",
      "Estimator: Naive Bayes\n",
      "Test set accuracy score: 0.813 \n",
      "\n",
      "Estimator: Random Forest\n",
      "Test set accuracy score: 0.611 \n",
      "\n",
      "Looking at 90/10 split\n",
      "\n",
      "Estimator: Support Vector Machine\n",
      "Test set accuracy score: 0.930 \n",
      "\n",
      "Estimator: Naive Bayes\n",
      "Test set accuracy score: 0.899 \n",
      "\n",
      "Estimator: Random Forest\n",
      "Test set accuracy score: 0.988 \n"
     ]
    }
   ],
   "source": [
    "accuracy2 = {}\n",
    "for i, item in enumerate(X_train):\n",
    "    \n",
    "    print(\"\\nLooking at\",  train_dict[i], \"split\")\n",
    "    accuracy2[train_dict[i]] = {}\n",
    "    for idx, pl in enumerate(pipelines):\n",
    "        print(\"\\nEstimator:\",  pipe_dict[idx])\n",
    "        pl.fit(X_train[i], y_train[i])\n",
    "        y_pred = pl.predict(X_test[i])\n",
    "        print('Test set accuracy score: %.3f ' % accuracy_score(y_test[i], y_pred))\n",
    "        accuracy2[train_dict[i]][pipe_dict[idx]] = accuracy_score(y_test[i], y_pred)\n",
    "        # end inner for over pipeline\n",
    "    #end outer for over data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>50/50</th>\n",
       "      <th>80/20</th>\n",
       "      <th>90/10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.791216</td>\n",
       "      <td>0.812819</td>\n",
       "      <td>0.899438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.604597</td>\n",
       "      <td>0.611083</td>\n",
       "      <td>0.988196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.809806</td>\n",
       "      <td>0.827375</td>\n",
       "      <td>0.929743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           50/50     80/20     90/10\n",
       "Naive Bayes             0.791216  0.812819  0.899438\n",
       "Random Forest           0.604597  0.611083  0.988196\n",
       "Support Vector Machine  0.809806  0.827375  0.929743"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = pd.DataFrame.from_dict(accuracy)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter sentence: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Idris heard of her mother's return with pleasure.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimator: Support Vector Machine\n",
      "According to Support Vector Machine the author is: ['MWS']\n",
      "\n",
      "Estimator: Naive Bayes\n",
      "According to Naive Bayes the author is: ['MWS']\n",
      "\n",
      "Estimator: Random Forest\n",
      "According to Random Forest the author is: ['MWS']\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter sentence: \")\n",
    "sent = input()\n",
    "sentence = pd.DataFrame({'text' : [sent]})\n",
    "\n",
    "for idx, pl in enumerate(pipelines):\n",
    "    print(\"\\nEstimator:\",  pipe_dict[idx])\n",
    "    pl.fit(X_train, y_train)\n",
    "    y_pred = pl.predict(sentence.text)\n",
    "    print(\"According to\", pipe_dict[idx], \"the author is:\", y_pred)\n",
    "    # end inner for over pipeline\n",
    "    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "Check nltk and sklearn versions: https://stackoverflow.com/questions/28501072/how-to-check-which-version-of-nltk-scikit-learn-installed\n",
    "Pipeline help: https://www.kdnuggets.com/2017/12/managing-machine-learning-workflows-scikit-learn-pipelines-part-1.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
