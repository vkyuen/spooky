{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting texts into CSV files.\n",
    "This file is responsible for taking .txt files of the story and splitting them into separate sentences.  To remove labels, manually, the header of the file will be removed.  For each sentence found, sentences with 2 or fewer words will be removed.  Assuming it will lines like 'Chapter II'.  And removing all whitespace that is not a space. \n",
    "\n",
    "In the menus, it assumes the user will follow the prompt as indicated.  There is no check to ensure the user is entering valid information at this time. \n",
    "\n",
    "The assumed folder structure for this program is that this file is in the current working directory.  In the same directory, there is a folder named data, inside of data there are two folders Books and author.  Inside Books, are folders MWS, EAP, HPL which contains .txt files of the author's work.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "sent_dector = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "isTesting = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## openFile\n",
    "This function tries to open the file, given a file name.  It takes in two parameters:  the file name and what mode to open in, by default for this project, the mode will be set to read mode.  It will return a file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openFile (filename, mode = \"r\"):\n",
    "    if(isTesting):\n",
    "        print(\"openFile: \", filename,\"\\n\")\n",
    "        \n",
    "    try:\n",
    "        file = open(filename, mode)\n",
    "        return file\n",
    "                                        \n",
    "    except IOError:\n",
    "        print(\"An unexpected IO error occured in openFile.\")\n",
    "    except:\n",
    "        print(\"An unexpected error occured in openFile.\")\n",
    "    \n",
    "    #end textToVariable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fileToLines\n",
    "This function will take in the opened file and return a the text from the file as a single string. Replacing line breaks with spaces, and removing multiple spaces.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileToLines(file):\n",
    "    lines = file.read().replace(\"\\n\", \" \")\n",
    "    lines = \" \".join(lines.split())\n",
    "    file.close()\n",
    "    return lines\n",
    "    #end fileToLines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitBySentence\n",
    "This function will take a string and return a list of the string split into sentence. Removing the leading and trailing spaces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitBySentence(lines):\n",
    "    if(isTesting):\n",
    "        print(\"\\nin  splitBySentence\\n\")\n",
    "    tokens = sent_dector.tokenize(lines.strip())\n",
    "    \n",
    "    return tokens\n",
    "    #end splitBySentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## listToDf\n",
    "This function will take in a list of tokens and put it into a pandas data frame and append the list of tokens to the original data frame. Returning the original data frame with the new text appended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToDf(tokens, original):\n",
    "    if(isTesting):\n",
    "        print(\"\\nin listToDf \\n\")\n",
    "    df = pd.DataFrame(tokens)\n",
    "    df.columns = [\"text\"]\n",
    "    \n",
    "    if(original.empty):\n",
    "        original = df\n",
    "    else:\n",
    "        original.append(df, ignore_index = True)\n",
    "        \n",
    "        \n",
    "    return original\n",
    "    #listToDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## removeShort\n",
    "This function will take in a data frame, and will remove sentences with the minimum number of words in the text field.  The variable min is set to 3 by default, unless the function is called with a different value specified. It will return the data frame.  This is done to help remove chapter labels.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeShort(dataFrame, min = 3):\n",
    "    \n",
    "    if(isTesting):\n",
    "        print(\"\\nin removeShort\\n\")\n",
    "        print(dataFrame)\n",
    "    \n",
    "    count = dataFrame[\"text\"].str.split().str.len()\n",
    "    ~(count == min)\n",
    "    if(isTesting):\n",
    "        print(\"count is: \\n\", count)\n",
    "    \n",
    "    dropped = dataFrame[~(count <= min)].copy()\n",
    "    dropped = dropped.reset_index(drop = True)\n",
    "    if(isTesting):\n",
    "        print(\"\\nafter dropped\")\n",
    "        print(dropped)\n",
    "        \n",
    "    return dropped\n",
    "    # end removeShort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if(isTesting):\n",
    "#     data = pd.DataFrame({'text': ['hello my name is','hey', 'hello world', 'help me please!']})\n",
    "#     removeShort(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## addAuthor\n",
    "This function will take in a data frame and the string representation of the author, in this project MWS, EAP, HPL.  It will return a dataframe with an additional autorh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addAuthor(df, author):\n",
    "    if(isTesting):\n",
    "        print(\"\\n \\n\")\n",
    "    df[\"author\"] = author\n",
    "    return df\n",
    "    # end addAuthor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getPath\n",
    "This function will take in a list of stings that represent the folders from the current working directory.  It will return a string representation of the path to a file or where a file should be created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPath(folderSystem, path = os.getcwd()):\n",
    "    for string in folderSystem:\n",
    "        path = os.path.join(path, string)\n",
    "    \n",
    "    if(isTesting):\n",
    "        print(\"getPath built:\", path)\n",
    "        \n",
    "    return path\n",
    "    # end getPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dfToCsv\n",
    "This function will take in a data frame and a string representation of the file name.  It will write the data frame to file specified by the filename. ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfToCsv(df, filename):\n",
    "    if(isTesting):\n",
    "        print(\"\\nin difToCsv \\n\")\n",
    "    file = None\n",
    "    \n",
    "    if(isTesting):\n",
    "        print(\"file path: \", filename)\n",
    "    \n",
    "    if(os.path.exists(filename)):\n",
    "        file = openFile(filename, \"a\")\n",
    "        df.to_csv(file, header = False, index = False)\n",
    "        file.close()\n",
    "    else:\n",
    "        file = openFile(filename, \"a\")\n",
    "        df.to_csv( file, index = False)\n",
    "        file.close()\n",
    "    # end dfToCsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## readAndCreate\n",
    "This function will prompt the use through the process of reading in a .txt file and saving it as a .csv file. Assuming the .txt files are located in data/Books/[author initial] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAndCreate():\n",
    "    if(isTesting):\n",
    "        print(\"\\nin readAndCreate\\n\")\n",
    "        \n",
    "    \n",
    "    \n",
    "    # get folder name\n",
    "    print(\"Enter author's name (MWS, EAP, HPL)\")\n",
    "    author = input()\n",
    "    \n",
    "    folderPath = os.path.join(os.getcwd(), \"data\", \"Books\", author)\n",
    "    \n",
    "    #setup loop to go through files\n",
    "    #for filename in os.listdir(folderPath):\n",
    "    for filename in glob.glob(os.path.join(folderPath, '*.txt')):\n",
    "        if(isTesting):\n",
    "            print(\"List is:\", os.path.join(folderPath, '*.txt'))\n",
    "        \n",
    "        currentDf = pd.DataFrame()\n",
    "        #open file\n",
    "        currentFile = openFile(filename)\n",
    "        #create string of text\n",
    "        lines = fileToLines(currentFile)\n",
    "        #tokenize string\n",
    "        tokens = splitBySentence(lines)\n",
    "        #list -> df\n",
    "        currentDf = listToDf(tokens, currentDf)\n",
    "        #end filename loop\n",
    "    \n",
    "        #done with all files\n",
    "        #delete short sentences\n",
    "        currentDf = removeShort(currentDf)\n",
    "        #label author\n",
    "        addAuthor(currentDf, author)\n",
    "        #write to csv\n",
    "        csvName = author + \".csv\"\n",
    "        folderList = [\"data\", \"author\", csvName]\n",
    "        folderPath = getPath(folderList)\n",
    "        dfToCsv(currentDf, folderPath)\n",
    "    \n",
    "# readAndCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge()\n",
    "This function will merge the number of files specified in the parameters.  The files to be merged have been specified by the list of file names specified in the list of the second parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(number, listOfFiles):\n",
    "    listOfDf = []\n",
    "    for i in range(number):\n",
    "        listOfDf.append(pd.read_csv(listOfFiles[i]))\n",
    "        # end for\n",
    "    merged = pd.concat(listOfDf, ignore_index = True)\n",
    "    return merged\n",
    "    # end merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getMergeInfo()\n",
    "This function will prompt users for more information an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMergeInfo():\n",
    "    print(\"How many files do you want to merge? \")\n",
    "    fileCount = int(input())\n",
    "    \n",
    "    print(\"\\nAre the files the .csv files in the data/author folder? (y / any other key)\")\n",
    "    isAssumedFiles = input()\n",
    "        \n",
    "    listOfFile = []\n",
    "    for number in range(0,fileCount):\n",
    "        if (isAssumedFiles == 'y'):\n",
    "            \n",
    "            print(\"Which .csv file in data/author do you want to merge (please don't include .csv)?\")\n",
    "            name = input()\n",
    "            fullPath = [\"data\", \"author\", name + \".csv\"]\n",
    "            listOfFile.append(getPath(fullPath))\n",
    "        else:\n",
    "            print(\"Please enter the full path of the file you want to merge: \")\n",
    "            filePath = input()\n",
    "            listOfFile.append(filePath)\n",
    "        # end for loop\n",
    "\n",
    "    master = merge(fileCount, listOfFile)\n",
    "    # master.insert(0, \"id\", range(1, len(master)+1))\n",
    "    if(isTesting):\n",
    "        print(\"master is: \",master)\n",
    "    print(\"Wrtting merged file to master.csv in the data folder\")\n",
    "    \n",
    "    mergeFolder = [\"data\", \"master.csv\"]\n",
    "    mergePath = getPath(mergeFolder)\n",
    "    dfToCsv(master, mergePath)\n",
    "    \n",
    "    # end getMergeInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyAuthor():\n",
    "    testPath = [\"data\", \"test.csv\"]\n",
    "    masterPath = [\"data\", \"master.csv\"]\n",
    "    test = pd.read_csv(getPath(testPath))\n",
    "    master = pd.read_csv(getPath(masterPath))\n",
    "    \n",
    "    test[\"author\"] = None\n",
    "    \n",
    "    for i, row in test.iterrows():\n",
    "\n",
    "        # for each row... \n",
    "        current = test.iloc[i]\n",
    "        result = master[master[\"text\"].str.match(current[\"text\"])]\n",
    "        countOfResult = result[\"text\"].count()\n",
    "\n",
    "        if(countOfResult == 1):\n",
    "            author = result.iloc[0][\"author\"]\n",
    "            test.at[i, \"author\"] = author\n",
    "        elif (countOfResult == 0):\n",
    "            if(isTesting):\n",
    "                print(\"\\ntext not in master\\n\")\n",
    "        else:\n",
    "            if(isTesting):\n",
    "                print(\"\\nMore than one match\\n\")\n",
    "\n",
    "        if(isTesting):\n",
    "            print(test.iloc[i])\n",
    "         \n",
    "    # end for over test\n",
    "    \n",
    "    print(\"\\ncounting how many rows are labeled and empty\\n\")\n",
    "\n",
    "    print(test.count())\n",
    "    labeledTest = test.copy()\n",
    "    print(labeledTest.head(5))\n",
    "    \n",
    "    masterPath = [\"data\", \"\"]\n",
    "    masterPath = getPath(masterPath)\n",
    "\n",
    "    dfToCsv(labeledTest, masterPath + \"fullLabeledTest.csv\")\n",
    "\n",
    "    print(\"dropped n/a\")\n",
    "    labeledTest[labeledTest.astype(str).ne(\"None\").all(1)]\n",
    "    if(isTesting):\n",
    "        print(labeledTest)\n",
    "    print(labeledTest.head(5))\n",
    "    labeledTest.isna()\n",
    "    droppedLabel = labeledTest.dropna()\n",
    "    \n",
    "    dfToCsv(droppedLabel, masterPath + \"labeledTest.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## printMenuOptions\n",
    "This function will print out the menu options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMenuOptions():\n",
    "    print()\n",
    "    print(\"0 - Exit program\")\n",
    "    print(\"1 - Read .txt file and save to .csv for folder\")\n",
    "    print(\"2 - Combine MWS.csv, EAP.csv, and HPL.csv files\")\n",
    "    print(\"3 - Use master.csv to match author\")\n",
    "    print()\n",
    "    # end printMenuOptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## menu\n",
    "This function starts the converting process.  It will display menus, and allow the user to specify which files to convert into .csv files.  It also gives users the ability to combine different csv fies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 - Exit program\n",
      "1 - Read .txt file and save to .csv for folder\n",
      "2 - Combine MWS.csv, EAP.csv, and HPL.csv files\n",
      "3 - Use master.csv to match author\n",
      "\n",
      "Make a selection:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "More than one match\n",
      "\n",
      "\n",
      "More than one match\n",
      "\n",
      "\n",
      "More than one match\n",
      "\n",
      "\n",
      "More than one match\n",
      "\n",
      "\n",
      "More than one match\n",
      "\n",
      "\n",
      "More than one match\n",
      "\n",
      "\n",
      "counting how many rows are labeled and empty\n",
      "\n",
      "id        8392\n",
      "text      8392\n",
      "author    4213\n",
      "dtype: int64\n",
      "           id                                               text author\n",
      "0     id02310  Still, as I urged our leaving Ireland with suc...    MWS\n",
      "1     id24541  If a fire wanted fanning, it could readily be ...   None\n",
      "2     id00134  And when they had broken down the frail door t...    HPL\n",
      "3     id27757  While I was thinking how I should possibly man...   None\n",
      "4     id04081  I am not sure to what limit his knowledge may ...    EAP\n",
      "5     id27337  \"The thick and peculiar mist, or smoke, which ...   None\n",
      "6     id24265  That which is not matter, is not at all unless...   None\n",
      "7     id25917  I sought for repose although I did not hope fo...    MWS\n",
      "8     id04951  Upon the fourth day of the assassination, a pa...    EAP\n",
      "9     id14549         \"The tone metaphysical is also a good one.   None\n",
      "10    id22505  These, the offspring of a later period, stood ...   None\n",
      "11    id24002  What kept him from going with her and Brown Je...   None\n",
      "12    id18982  Persuading the widow that my connexion with he...   None\n",
      "13    id15181  When I arose trembling, I know not how much la...    HPL\n",
      "14    id21888  And by the shores of the river Zaire there is ...    EAP\n",
      "15    id12035  Idris heard of her mother's return with pleasure.    MWS\n",
      "16    id17991  I say this proudly, but with tears in my eyes ...   None\n",
      "17    id10707  But let us glance at the treatise Ah \"Ability ...   None\n",
      "18    id07101  \"What a place is this that you inhabit, my son...   None\n",
      "19    id00345  At his nod I took one of the latter and seated...    HPL\n",
      "20    id05912  No one doubted now that the mystery of this mu...   None\n",
      "21    id13443  But although, in one or two instances, arrests...   None\n",
      "22    id09248  Festivity, and even libertinism, became the or...    MWS\n",
      "23    id17542        For I am Iranon, who was a Prince in Aira.\"   None\n",
      "24    id06995  \"Gaze not on the star, dear, generous friend,\"...    MWS\n",
      "25    id25159  I am serious in asserting that my breath was e...   None\n",
      "26    id25729  The thing will haunt me, for who can say the e...    HPL\n",
      "27    id26949  Before each of the party lay a portion of a sk...   None\n",
      "28    id27191  If she had been bred in that sphere of life to...    MWS\n",
      "29    id07668  Or, if this mode of speech offend you, let me ...    MWS\n",
      "...       ...                                                ...    ...\n",
      "8362  id22510  Then again he distracted my thoughts from my s...    MWS\n",
      "8363  id19204  Upon the whole, whether happily or unhappily, ...   None\n",
      "8364  id05758  He was not allowed to finish this speech in tr...   None\n",
      "8365  id27063  His looks were wild with terror, and he spoke ...    EAP\n",
      "8366  id11773  By the quantity of provision which I had consu...    MWS\n",
      "8367  id11562  I hurled after the scoundrel these vehement wo...   None\n",
      "8368  id16208  Notwithstanding the hazardous object of our jo...    MWS\n",
      "8369  id04036  I felt the greatest eagerness to hear the prom...    MWS\n",
      "8370  id26159  But in the expression of the countenance, whic...   None\n",
      "8371  id26777  Its decorations were rich, yet tattered and an...    EAP\n",
      "8372  id08501  He directed my attention to some object agains...    EAP\n",
      "8373  id11216  Hey? Haow'd ye like to hear the haowlin' night...   None\n",
      "8374  id03410  She was buried not in a vault, but in an ordin...   None\n",
      "8375  id04537  In company with this sprightly and clever Gree...    MWS\n",
      "8376  id26628  In this unnerved in this pitiable condition I ...   None\n",
      "8377  id01586  He was a scoundrel, and I don't blame you for ...   None\n",
      "8378  id13421  But why should I dwell upon the incidents that...    MWS\n",
      "8379  id26084  In the streets were spears of long grass, and ...   None\n",
      "8380  id05375  When I first sought it, it was the love of vir...    MWS\n",
      "8381  id23212  But it is in matters beyond the limits of mere...    EAP\n",
      "8382  id15980  \"I may say an excellently well constructed house.   None\n",
      "8383  id11719  Across a covered bridge one sees a small villa...    HPL\n",
      "8384  id13109  You cannot take up a common newspaper in which...   None\n",
      "8385  id07156  Consoling myself with this reflection, I was m...   None\n",
      "8386  id04893  Yet we laughed and were merry in our proper wa...   None\n",
      "8387  id11749         All this is now the fitter for my purpose.   None\n",
      "8388  id10526                 I fixed myself on a wide solitude.    MWS\n",
      "8389  id13477  It is easily understood that what might improv...   None\n",
      "8390  id13761  Be this as it may, I now began to feel the ins...    EAP\n",
      "8391  id04282  Long winded, statistical, and drearily genealo...   None\n",
      "\n",
      "[8392 rows x 3 columns]\n",
      "dropped n/a\n",
      "\n",
      "0 - Exit program\n",
      "1 - Read .txt file and save to .csv for folder\n",
      "2 - Combine MWS.csv, EAP.csv, and HPL.csv files\n",
      "3 - Use master.csv to match author\n",
      "\n",
      "Make a selection:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending program\n"
     ]
    }
   ],
   "source": [
    "def menu():\n",
    "    choice = 9\n",
    "    \n",
    "    while choice != 0:\n",
    "        printMenuOptions()\n",
    "        print(\"Make a selection:\")\n",
    "        choice = input()\n",
    "        choice = int(choice)\n",
    "        if choice == 1:\n",
    "            readAndCreate()\n",
    "            # end choice =1\n",
    "        elif choice == 2:\n",
    "            getMergeInfo()\n",
    "            # end choice == 2\n",
    "        elif choice == 3:\n",
    "            classifyAuthor()\n",
    "            # end choice == 3\n",
    "        elif choice == 0:\n",
    "            print(\"Ending program\")\n",
    "            # end choice == 0\n",
    "        else:\n",
    "            print(choice, \"is not a valid choice.\\n\")\n",
    "        # end choice\n",
    "    # end menu\n",
    "menu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if(isTesting):\n",
    "#     targetddFolder = os.path.join(os.getcwd(), \"data\", \"\")\n",
    "#     listOfFile = [targetFolder + \"MWS.csv\", targetFolder + \"EAP.csv\", targetFolder + \"HPL.csv\"]\n",
    "#     print(listOfFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if(isTesting):\n",
    "#     print(os.getcwd())\n",
    "#     currentBook = \"Berenice.txt\"\n",
    "#     print(os.path.join(os.getcwd(), \"data\", \"Books\", \"EAP\", currentBook))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python path help: https://automatetheboringstuff.com/chapter8/\n",
    "Getting the working directory path: https://stackoverflow.com/questions/3430372/how-to-get-full-path-of-current-files-directory-in-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
