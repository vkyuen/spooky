{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic simplest version\n",
    "In this file, using tf-idf with SVM abd Naive Bayes.  With full training set\n",
    "\n",
    "Working with nltk version 3.2.5 and scikit-learn version 0.20.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# SVM\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# NB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # step by step reference, no pipeline\n",
    "\n",
    "# # count words\n",
    "# count_vect = CountVectorizer()\n",
    "# X_train_count = count_vect.fit_transform(X_train.text)\n",
    "# X_train_count.shape\n",
    "\n",
    "# # tf-idf\n",
    "# tfidf_transformer = TfidfTransformer()\n",
    "# X_train_tfidf = tfidf_transformer.fit_transform(X_train_count)\n",
    "# X_train_tfidf.shape\n",
    "\n",
    "# # NB\n",
    "# clf = MultinomialNB().fit(X_train_tfidf, X_train.author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "Using pipelines to help speed things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = Pipeline([(\"vect\", CountVectorizer()),\n",
    "                        (\"tfidf\", TfidfTransformer()),\n",
    "                        (\"clf-svm\", SGDClassifier(loss = \"hinge\", penalty = \"l2\",\n",
    "                                                tol = 1e-3, \n",
    "                                                random_state = 42)),])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clf = Pipeline([(\"vect\", CountVectorizer()),\n",
    "                    (\"tfidf\", TfidfTransformer()),\n",
    "                    (\"clf- nb\", MultinomialNB(),)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = Pipeline([(\"vect\", CountVectorizer()),\n",
    "                    (\"tfidf\", TfidfTransformer()),\n",
    "                    (\"clf-rf\", RandomForestClassifier(random_state = 42, n_estimators = 10),)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automate pipelines\n",
    "Create lists and a dictionary to help iterate through the fit and predict parts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = [svm_clf, nb_clf, rf_clf]\n",
    "pipe_dict = {0: \"Support Vector Machine\", 1: \"Naive Bayes\", 2: \"Random Forest\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting features, using bag of words model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = os.path.join(os.getcwd(), \"data\", \"\")\n",
    "train = pd.read_csv(dataPath + \"train.csv\")\n",
    "if(verbose):\n",
    "    print(train.head(5))\n",
    "test = pd.read_csv(dataPath + \"labeledTest.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        EAP\n",
       "1        HPL\n",
       "2        EAP\n",
       "3        MWS\n",
       "4        HPL\n",
       "5        MWS\n",
       "6        EAP\n",
       "7        EAP\n",
       "8        EAP\n",
       "9        MWS\n",
       "10       MWS\n",
       "11       EAP\n",
       "12       HPL\n",
       "13       HPL\n",
       "14       EAP\n",
       "15       MWS\n",
       "16       EAP\n",
       "17       MWS\n",
       "18       EAP\n",
       "19       HPL\n",
       "20       EAP\n",
       "21       HPL\n",
       "22       EAP\n",
       "23       EAP\n",
       "24       EAP\n",
       "25       EAP\n",
       "26       EAP\n",
       "27       EAP\n",
       "28       HPL\n",
       "29       HPL\n",
       "        ... \n",
       "19549    MWS\n",
       "19550    EAP\n",
       "19551    EAP\n",
       "19552    EAP\n",
       "19553    EAP\n",
       "19554    HPL\n",
       "19555    EAP\n",
       "19556    EAP\n",
       "19557    EAP\n",
       "19558    EAP\n",
       "19559    HPL\n",
       "19560    EAP\n",
       "19561    HPL\n",
       "19562    EAP\n",
       "19563    MWS\n",
       "19564    EAP\n",
       "19565    EAP\n",
       "19566    MWS\n",
       "19567    EAP\n",
       "19568    EAP\n",
       "19569    MWS\n",
       "19570    MWS\n",
       "19571    HPL\n",
       "19572    EAP\n",
       "19573    MWS\n",
       "19574    EAP\n",
       "19575    EAP\n",
       "19576    EAP\n",
       "19577    EAP\n",
       "19578    HPL\n",
       "Name: author, Length: 39158, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train = train.text\n",
    "y_train = train.author\n",
    "X_test = test.text\n",
    "y_test = train.author\n",
    "\n",
    "X_train.append(X_train)\n",
    "y_train.append(y_train)\n",
    "X_test.append(X_test)\n",
    "y_test.append(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "X_train.append(X50_train)\n",
    "y_train.append(y50_train)\n",
    "X_test.append(X50_test)\n",
    "y_test.append(y50_test)\n",
    "    \n",
    "X_train.append(X80_train)\n",
    "y_train.append(y20_train)\n",
    "X_test.append(X80_test)\n",
    "y_test.append(y20_test)\n",
    "    \n",
    "X_train.append(X90_train)\n",
    "y_train.append(y10_train)\n",
    "X_test.append(X90_train)\n",
    "y_test.append(y10_train)\n",
    "\n",
    "train_dict = {0: \"50/50\", 1: \"80/20\", 2: \"90/10\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Looking at 50/50 split\n",
      "\n",
      "Estimator: Support Vector Machine\n",
      "Test set accuracy score: 0.807 \n",
      "\n",
      "Estimator: Naive Bayes\n",
      "Test set accuracy score: 0.778 \n",
      "\n",
      "Estimator: Random Forest\n",
      "Test set accuracy score: 0.599 \n",
      "\n",
      "Looking at 80/20 split\n",
      "\n",
      "Estimator: Support Vector Machine\n",
      "Test set accuracy score: 0.832 \n",
      "\n",
      "Estimator: Naive Bayes\n",
      "Test set accuracy score: 0.816 \n",
      "\n",
      "Estimator: Random Forest\n",
      "Test set accuracy score: 0.594 \n",
      "\n",
      "Looking at 90/10 split\n",
      "\n",
      "Estimator: Support Vector Machine\n",
      "Test set accuracy score: 0.927 \n",
      "\n",
      "Estimator: Naive Bayes\n",
      "Test set accuracy score: 0.899 \n",
      "\n",
      "Estimator: Random Forest\n",
      "Test set accuracy score: 0.988 \n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(X_train):\n",
    "    \n",
    "    print(\"\\nLooking at\",  train_dict[i], \"split\")\n",
    "    accuracy[train_dict[i]] = {}\n",
    "    for idx, pl in enumerate(pipelines):\n",
    "        print(\"\\nEstimator:\",  pipe_dict[idx])\n",
    "        pl.fit(X_train[i], y_train[i])\n",
    "        y_pred = pl.predict(X_test[i])\n",
    "        print('Test set accuracy score: %.3f ' % accuracy_score(y_test[i], y_pred))\n",
    "        accuracy[train_dict[i]][pipe_dict[idx]] = accuracy_score(y_test[i], y_pred)\n",
    "        # end inner for over pipeline\n",
    "    #end outer for over data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Looking at 50/50 split\n",
      "\n",
      "Estimator: Support Vector Machine\n",
      "Test set accuracy score: 0.807 \n",
      "\n",
      "Estimator: Naive Bayes\n",
      "Test set accuracy score: 0.778 \n",
      "\n",
      "Estimator: Random Forest\n",
      "Test set accuracy score: 0.599 \n",
      "\n",
      "Looking at 80/20 split\n",
      "\n",
      "Estimator: Support Vector Machine\n",
      "Test set accuracy score: 0.832 \n",
      "\n",
      "Estimator: Naive Bayes\n",
      "Test set accuracy score: 0.816 \n",
      "\n",
      "Estimator: Random Forest\n",
      "Test set accuracy score: 0.594 \n",
      "\n",
      "Looking at 90/10 split\n",
      "\n",
      "Estimator: Support Vector Machine\n",
      "Test set accuracy score: 0.927 \n",
      "\n",
      "Estimator: Naive Bayes\n",
      "Test set accuracy score: 0.899 \n",
      "\n",
      "Estimator: Random Forest\n",
      "Test set accuracy score: 0.988 \n"
     ]
    }
   ],
   "source": [
    "accuracy2 = {}\n",
    "for i, item in enumerate(X_train):\n",
    "    \n",
    "    print(\"\\nLooking at\",  train_dict[i], \"split\")\n",
    "    accuracy2[train_dict[i]] = {}\n",
    "    for idx, pl in enumerate(pipelines):\n",
    "        print(\"\\nEstimator:\",  pipe_dict[idx])\n",
    "        pl.fit(X_train[i], y_train[i])\n",
    "        y_pred = pl.predict(X_test[i])\n",
    "        print('Test set accuracy score: %.3f ' % accuracy_score(y_test[i], y_pred))\n",
    "        accuracy2[train_dict[i]][pipe_dict[idx]] = accuracy_score(y_test[i], y_pred)\n",
    "        # end inner for over pipeline\n",
    "    #end outer for over data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>50/50</th>\n",
       "      <th>80/20</th>\n",
       "      <th>90/10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.777937</td>\n",
       "      <td>0.815884</td>\n",
       "      <td>0.899495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.598570</td>\n",
       "      <td>0.594484</td>\n",
       "      <td>0.987742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.806639</td>\n",
       "      <td>0.831716</td>\n",
       "      <td>0.926508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           50/50     80/20     90/10\n",
       "Naive Bayes             0.777937  0.815884  0.899495\n",
       "Random Forest           0.598570  0.594484  0.987742\n",
       "Support Vector Machine  0.806639  0.831716  0.926508"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = pd.DataFrame.from_dict(accuracy)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "Check nltk and sklearn versions: https://stackoverflow.com/questions/28501072/how-to-check-which-version-of-nltk-scikit-learn-installed\n",
    "Pipeline help: https://www.kdnuggets.com/2017/12/managing-machine-learning-workflows-scikit-learn-pipelines-part-1.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
